{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nti41m2yBRFh"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import pylab\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import groupby\n",
        "from scipy.stats import kendalltau\n",
        "from IPython.display import display, HTML\n",
        "from tabulate import tabulate"
      ],
      "metadata": {
        "id": "aPc8jyTEBkh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path of datasets\n",
        "\n",
        "KARATE = '/content/drive/MyDrive/Complex Networks Project/karate.txt'\n",
        "JAZZ = '/content/drive/MyDrive/Complex Networks Project/Jazz.txt'\n",
        "POLBOOKS = '/content/drive/MyDrive/Complex Networks Project/polbooks.txt'"
      ],
      "metadata": {
        "id": "xgSKINsuChjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------\n",
        "<h1>GLI<h1>\n"
      ],
      "metadata": {
        "id": "9J2x7D5SETkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the dataset here\n",
        "path = KARATE\n",
        "\n",
        "\n",
        "def simjkd(u, v):\n",
        "    set_v = set(G.neighbors(v))\n",
        "    set_v.add(v)\n",
        "    set_u = set(G.neighbors(u))\n",
        "    set_u.add(u)\n",
        "    jac = len(set_v & set_u) * 1.0 / len(set_v | set_u)\n",
        "    return jac\n",
        "\n",
        "# Jaccard similarity coefficient\n",
        "#    jac = (len(set_v & set_u) - 2) * 1.0 / (len(set_v | set_u) - 2)  # Neighborhood redundancy\n",
        "#    jac = 1 / (1 + abs(len(set_v) - len(set_u)))  # Euclidean distance - measuring similarity\n",
        "#    jac = len(set_v) * len(set_u) / (pow(len(set_v), 2) + pow(len(set_u), 2) - len(set_v) * len(set_u))\n",
        "#    Generalized Jaccard similarity\n",
        "\n",
        "\n",
        "G = nx.Graph()\n",
        "\n",
        "with open(path) as file:\n",
        "    for line in file:\n",
        "        head, tail = [int(x) for x in line.split()]\n",
        "        G.add_edge(head, tail)\n",
        "\n",
        "nums = G.number_of_nodes()  # Number of nodes\n",
        "print('Total number of nodes', nums)\n",
        "\n",
        "G.remove_edges_from(nx.selfloop_edges(G))\n",
        "k_shell = nx.core_number(G)\n",
        "print('k_shell:', k_shell)\n",
        "\n",
        "maxKshell = max(k_shell.values())  # Using max() to find the maximum value in the k_shell dictionary\n",
        "minKshell = min(k_shell.values())  # Using min() to find the minimum value in the k_shell dictionary\n",
        "maxD = max(dict(G.degree()).values())\n",
        "print(\"maxD\", maxD)\n",
        "\n",
        "def getCountKshell(G):  # Parameter G represents the graph\n",
        "    node = G.nodes()\n",
        "    print(\"node=\", node)\n",
        "    ks_classfity = [dict(g) for k, g in groupby(sorted(nx.core_number(G).items(), key=by_value), by_value)]\n",
        "    print(ks_classfity)\n",
        "    dicts = {}\n",
        "    for index in node:\n",
        "        list = []\n",
        "        print(\"index=\", index)\n",
        "        for ks_value in ks_classfity:\n",
        "            dictss = {}\n",
        "            for k, v in ks_value.items():\n",
        "                if k == index:\n",
        "                    continue\n",
        "                print(\"k=,length=\", k, nx.shortest_path_length(G, source=index, target=k))\n",
        "                dictss[k] = nx.shortest_path_length(G, source=index, target=k)\n",
        "            list.append(dictss)\n",
        "        dicts[index] = list\n",
        "    return dicts\n",
        "\n",
        "\n",
        "d = []\n",
        "\n",
        "# Accumulated sum of influence factor * (k-shell value + degree) + self-degree\n",
        "res = {}\n",
        "for nodev in G.nodes():\n",
        "    value = 0\n",
        "\n",
        "    for nodeu in G.neighbors(nodev):\n",
        "        xs = simjkd(nodev, nodeu)\n",
        "        value += xs * (G.degree(nodeu)) + k_shell[nodeu]\n",
        "    res[nodev] = value / maxD + G.degree(nodev) + k_shell[nodev]\n",
        "\n",
        "print(res)\n",
        "\n",
        "for key in res.keys():\n",
        "    rest = res[key]\n",
        "    d.append((key, rest))\n",
        "\n",
        "sortNum = sorted(d, key=lambda x: x[1], reverse=True)"
      ],
      "metadata": {
        "id": "lgmTOZdGEDyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort by value\n",
        "nodelist = []\n",
        "GLI_sortNum = sorted(res.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Save the result to a file\n",
        "for key in GLI_sortNum:\n",
        "    nodelist.append(key.__getitem__(0))\n",
        "print(nodelist)\n",
        "\n",
        "output_path = '/content/drive/MyDrive/Complex Networks Project/output_value'\n",
        "with open(output_path, \"w\") as f:\n",
        "    for key, val in sortNum:\n",
        "        f.write(str(key) + '\\t' + str(val) + \"\\n\")\n",
        "\n",
        "print(f\"File saved to {output_path}\")"
      ],
      "metadata": {
        "id": "_VJWkfGEVk0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We get the 15 most influencial nodes given by the GLI algorithm\n",
        "\n",
        "GLI_ranking = []\n",
        "for key in sortNum[:15]:\n",
        "  GLI_ranking.append(key.__getitem__(0))\n",
        "print(GLI_ranking)"
      ],
      "metadata": {
        "id": "lieFJABdBkEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort by node ID\n",
        "nodelist1 = []\n",
        "sortNum1 = sorted(res.items(), key=lambda x: x[0], reverse=False)\n",
        "\n",
        "# Save the result to a file\n",
        "for key in sortNum1:\n",
        "    nodelist1.append(key.__getitem__(0))\n",
        "print(nodelist1)\n",
        "\n",
        "output_path = '/content/drive/MyDrive/Complex Networks Project/output_nodeID'\n",
        "with open(output_path, \"w\") as f:\n",
        "    for key, val in sortNum:\n",
        "        f.write(str(key) + '\\t' + str(val) + \"\\n\")\n",
        "\n",
        "print(f\"File saved to {output_path}\")"
      ],
      "metadata": {
        "id": "-Pc1j9JgVlRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Different Models\n",
        "\n",
        "DC = nx.degree_centrality(G) #Degree centrality for local information\n",
        "BC = nx.betweenness_centrality(G) #Betweness centrality Global information\n",
        "k_shell = nx.core_number(G) # Global information"
      ],
      "metadata": {
        "id": "zab3m0OklZK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DC_sortNum = sorted(DC.items(), key=lambda x: x[1], reverse=True)\n",
        "BC_sortNum = sorted(BC.items(), key=lambda x: x[1], reverse=True)\n",
        "kshell_sortNum = sorted(k_shell.items(), key=lambda x: x[1], reverse=True)"
      ],
      "metadata": {
        "id": "u-URpflp_Syq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SIR Model parameters\n",
        "\n",
        "alpha = 0.02  # Infection probability\n",
        "recovery_probability = 1.0  # Recovery probability\n",
        "iterations = 1000  # Number of iterations per node\n",
        "\n",
        "def simulate_sir(graph, seed_node, alpha):\n",
        "\n",
        "    \"\"\"\n",
        "    Simulate the SIR model for a given seed node.\n",
        "    Returns the total number of infected nodes (F(t)) for one iteration.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize states\n",
        "    states = {node: \"S\" for node in graph.nodes()}  # All nodes are initially susceptible\n",
        "    states[seed_node] = \"I\"  # Seed node is infected\n",
        "\n",
        "    infected_count = 1  # Start with the seed node infected\n",
        "    infected_nodes = [seed_node]\n",
        "\n",
        "    while infected_nodes:\n",
        "        new_infections = []\n",
        "        # Spread the infection\n",
        "        for node in infected_nodes:\n",
        "            for neighbor in graph.neighbors(node):\n",
        "                if states[neighbor] == \"S\" and random.random() < alpha:\n",
        "                    states[neighbor] = \"I\"\n",
        "                    new_infections.append(neighbor)\n",
        "            # Node recovers\n",
        "            states[node] = \"R\"\n",
        "\n",
        "        infected_nodes = new_infections  # Update infected nodes\n",
        "        infected_count += len(new_infections)\n",
        "\n",
        "    return infected_count\n",
        "\n",
        "def SIR_ranked(G, alpha, iterations):\n",
        "\n",
        "  # Calculate average influence (F(t)) over 1000 iterations for each node\n",
        "  influence_scores = {}\n",
        "  for node in G.nodes():\n",
        "      total_influence = 0\n",
        "      for _ in range(iterations):\n",
        "          total_influence += simulate_sir(G, node, alpha)\n",
        "      influence_scores[node] = total_influence / iterations  # Average influence\n",
        "  # Rank nodes based on their average influence\n",
        "  return sorted(influence_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "Ranked_nodes = SIR_ranked(G, alpha, iterations)\n",
        "for i, key in enumerate(Ranked_nodes):\n",
        "  if i <= 15:\n",
        "    print(f\"Node {key[0]} | influence:  {key[1]}\")\n",
        "  else: break\n"
      ],
      "metadata": {
        "id": "TvJAtCnsCCG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a DataFrame for comparison\n",
        "df_comparison = pd.DataFrame({\n",
        "    'DC': [key[0] for key in DC_sortNum[:15]],\n",
        "    'BC': [key[0] for key in BC_sortNum[:15]],\n",
        "    'k-shell': [key[0] for key in kshell_sortNum[:15]],\n",
        "    'GLI': GLI_ranking[:15],\n",
        "    'SIR': [key[0] for key in Ranked_nodes[:15]]\n",
        "})\n",
        "\n",
        "#change the name of the file as you modified the path\n",
        "df_comparison.to_csv(f\"/content/drive/MyDrive/Complex Networks Project/Comparison table for {name}\", index=False)\n",
        "\n",
        "# Display the comparison table\n",
        "title = '<h2>Comparison Table for the network</h2>'\n",
        "display(HTML(title))\n",
        "print(tabulate(df_comparison, headers='keys', tablefmt='pretty'))"
      ],
      "metadata": {
        "id": "IA6lbmoWFmDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_str = \"\"\n",
        "if path == KARATE:\n",
        "    name_str = \"Karate\"\n",
        "elif path == JAZZ:\n",
        "    name_str = \"Jazz\"\n",
        "elif path == POLBOOKS:\n",
        "    name_str = \"Polbooks\"\n",
        "\n",
        "\n",
        "rankings = {\n",
        "    'DC': [key[0] for key in DC_sortNum[:15]],\n",
        "    'BC': [key[0] for key in BC_sortNum[:15]],\n",
        "    'k-shell': [key[0] for key in kshell_sortNum[:15]],\n",
        "    'GLI': GLI_ranking[:15],\n",
        "}\n",
        "\n",
        "# Initialize list to store results\n",
        "results = []\n",
        "\n",
        "# Simulate SIR and calculate Kendall's tau for each alpha and ranking\n",
        "alphas = np.arange(0.00, 0.12, 0.02)\n",
        "for alpha in alphas:\n",
        "    sir_ranking = [key[0] for key in SIR_ranked(G, alpha, iterations)[:15]]  # Replace SIR_ranked\n",
        "    for name, ranking in rankings.items():\n",
        "        tau = kendalltau(sir_ranking, ranking)\n",
        "        results.append({\"alpha\": alpha, \"method\": name, \"kendall_tau\": tau[0]})\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "for method in rankings.keys():\n",
        "    subset = df[df[\"method\"] == method]\n",
        "    plt.plot(subset[\"alpha\"], subset[\"kendall_tau\"], marker='o', label=method)\n",
        "\n",
        "# Customize the plot\n",
        "plt.title(f\"{name_str}\", fontsize=16)\n",
        "plt.xlabel(\"Infection Probability (α)\", fontsize=12)\n",
        "plt.ylabel(\"Kendall's τ\", fontsize=12)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.legend(title=\"Method\", fontsize=10)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Place the legend in the upper right corner\n",
        "plt.legend(title=\"Method\", fontsize=10, loc=\"upper right\")\n",
        "\n",
        "# Save and show the plot\n",
        "plt.savefig(f\"/content/drive/MyDrive/Complex Networks Project/kendall_tau_comparison_{name_str}.png\", dpi=300, bbox_inches = \"tight\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KaPwTEUR4kd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Load the uploaded images\n",
        "img1 = Image.open(\"/content/drive/MyDrive/Complex Networks Project/kendall_tau_comparison_Karate.png\")\n",
        "img2 = Image.open(\"/content/drive/MyDrive/Complex Networks Project/kendall_tau_comparison_Jazz.png\")\n",
        "img3 = Image.open(\"/content/drive/MyDrive/Complex Networks Project/kendall_tau_comparison_Polbooks.png\")\n",
        "\n",
        "# Create a figure with subplots\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))  # 1 row, 3 columns\n",
        "\n",
        "# Display each image in a subplot\n",
        "axs[0].imshow(img1)\n",
        "axs[0].axis(\"off\")  # Turn off axes\n",
        "\n",
        "axs[1].imshow(img2)\n",
        "axs[1].axis(\"off\")\n",
        "\n",
        "\n",
        "axs[2].imshow(img3)\n",
        "axs[2].axis(\"off\")\n",
        "\n",
        "\n",
        "# Adjust layout for spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the combined figure as a single image\n",
        "plt.savefig(\"/content/drive/MyDrive/Complex Networks Project/Comparion_Tau_Networks.png\", dpi=300, bbox_inches=\"tight\")\n",
        "\n",
        "# Show the figure\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LUhIIR4g7_c3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}